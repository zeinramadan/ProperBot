{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06afc42",
   "metadata": {},
   "source": [
    "# Wrapping the model as a reddit bot\n",
    "\n",
    "After training and saving the trained model, we want to wrap it as a reddit bot that produces a score for every post made on the subreddit r/ProperTechno as a post reply. We will use the Reddit API. Might need to do this in PyCharm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd78278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import time\n",
    "\n",
    "# create a Reddit instance\n",
    "reddit = praw.Reddit(client_id='your_client_id',\n",
    "                     client_secret='your_client_secret',\n",
    "                     user_agent='your_user_agent',\n",
    "                     username='your_username',\n",
    "                     password='your_password')\n",
    "\n",
    "# set up youtube_dl options\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'outtmpl': '%(title)s.%(ext)s',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192'\n",
    "    }]\n",
    "}\n",
    "\n",
    "# # Load the trained seqential model\n",
    "# model = keras.models.load_model('my_model.h5')\n",
    "# OR\n",
    "# Load the random forrest model\n",
    "with open('path/to/saved/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# specify the subreddit to search\n",
    "subreddit = reddit.subreddit('ProperTechno')\n",
    "\n",
    "# Read posted ids from file\n",
    "with open('posted_ids.txt', 'r') as f:\n",
    "    posted_ids = f.read().splitlines()\n",
    "\n",
    "# loop through the latest 20 posts in the subreddit\n",
    "for post in subreddit.new(limit=20):\n",
    "    if post.id in posted_ids:\n",
    "\n",
    "        # check if the post is a link post\n",
    "        if post.is_self == False:\n",
    "\n",
    "            # fetch the url of the post\n",
    "            url = post.url\n",
    "            if 'youtube.com' in url:\n",
    "                \n",
    "                # Download track\n",
    "                with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "                    ydl.download([url])\n",
    "                    \n",
    "                # Read audio file\n",
    "                track = 0 # To ad\n",
    "\n",
    "            # check if it's a bandcamp link\n",
    "            elif 'bandcamp.com' in url:\n",
    "                # initialize a BandcampDL object with the track URL\n",
    "                dl = bandcamp_dl.BandcampDL(track_url)\n",
    "\n",
    "                # get the track information\n",
    "                track_info = dl.get_track_info()\n",
    "\n",
    "                # get the direct download link of the track\n",
    "                track_download_link = dl.get_download_link(track_info)\n",
    "\n",
    "                # download the track to a file\n",
    "                dl.download(track_download_link, file_name=f\"{track_info['artist']} - {track_info['title']}.mp3\")\n",
    "\n",
    "                # Read audio file\n",
    "                track = 0 # To add\n",
    "            \n",
    "            # Load track\n",
    "            y, sr = librosa.load(track, res_type='kaiser_fast', mono=False)\n",
    "  \n",
    "            # Compute the mfcc features\n",
    "            mfccs = librosa.feature.mfcc(y, sr=sr, n_mfcc=40)\n",
    "            mfccs_scaled = np.mean(mfccs.T,axis=0)\n",
    "\n",
    "            # Predict the class using the trained model\n",
    "            prediction = model.predict_classes(mfccs_scaled.reshape(1,-1))\n",
    "\n",
    "            # Make the comment on the post\n",
    "            post.reply('Proper bot thinks this track is {} likely to be proper techno. Do you agree?'.format(prediction[0]))\n",
    "\n",
    "            # Append posted id to file\n",
    "            with open('posted_ids.txt', 'a') as f:\n",
    "                f.write(post.id + '\\n')\n",
    "\n",
    "            else:\n",
    "                print(\"Already posted on\", post.id)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"Post already processed\")\n",
    "        \n",
    "    # wait for a bit to avoid hitting the API too frequently\n",
    "    time.sleep(1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
