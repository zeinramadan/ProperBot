{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "\n",
    "# Load the dataset\n",
    "data_dir = 'data'\n",
    "\n",
    "# data = pd.read_csv(f'{data_dir}/audio_features_no_duplicates_new_normalized.csv')\n",
    "data = pd.read_csv(f'{data_dir}/audio_features_no_duplicates_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: Counter({0: 1752, 1: 1678})\n"
     ]
    }
   ],
   "source": [
    "# Exclude the first column (filename) and assume the last column is the label\n",
    "X = data.iloc[:, 1:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Check the distribution of labels\n",
    "label_distribution = collections.Counter(y)\n",
    "print(f\"Label distribution: {label_distribution}\")\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the classifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.30%\n",
      "Precision: 0.86\n",
      "Recall: 0.86\n",
      "F1 Score: 0.86\n",
      "Confusion Matrix:\n",
      "[[430  73]\n",
      " [ 68 458]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       503\n",
      "           1       0.86      0.87      0.87       526\n",
      "\n",
      "    accuracy                           0.86      1029\n",
      "   macro avg       0.86      0.86      0.86      1029\n",
      "weighted avg       0.86      0.86      0.86      1029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path)\n",
    "\n",
    "    # Extract features\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr).T, axis=0)\n",
    "    zero_crossings = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    rms_energy = np.mean(librosa.feature.rms(y=y))\n",
    "\n",
    "    # Combine all features into a single array\n",
    "    features = np.hstack([mfccs, chroma, spectral_contrast, zero_crossings, spectral_bandwidth, rms_energy])\n",
    "\n",
    "    return features\n",
    "\n",
    "def predict_track(file_path, model):\n",
    "\n",
    "    # Extract features from the audio file\n",
    "    features = extract_features(file_path)\n",
    "    \n",
    "    # Convert features to a DataFrame with the same columns as used in training\n",
    "    feature_df = pd.DataFrame([features])\n",
    "\n",
    "    \n",
    "    # Make a prediction and get probabilities\n",
    "    label = model.predict(feature_df)\n",
    "    probabilities = model.predict_proba(feature_df)\n",
    "    \n",
    "    return label,probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions on unseen track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rene Wise - Lakota Fox.mp3 is proper! Label is 1 with a probability of 0.885\n",
      "Kike Pravda - Main Control [tZcM4ytxSGc].mp3 is proper! Label is 1 with a probability of 0.865\n",
      "Beatrice - I'm Not From Here.mp3 is proper! Label is 1 with a probability of 0.76\n",
      "Lowerzone - Verknipt People.mp3 is not proper! Label is 0 with a probability of 0.675\n",
      "Mark Dekoda - Rave Harder Techno Bass.mp3 is not proper! Label is 0 with a probability of 0.62\n",
      "09 - Step To Enchantment (Stringent).mp3 is proper! Label is 1 with a probability of 0.685\n",
      "Kaiser (K S R) - Driving In A Fast Tool.mp3 is proper! Label is 1 with a probability of 0.905\n",
      "Jeff Mills - Step to enchantment [eLtnhsLwSZE].mp3 is not proper! Label is 0 with a probability of 0.595\n",
      "Voorman - Surface Scatter.mp3 is proper! Label is 1 with a probability of 0.87\n",
      "Stef Mendesidis - Crime and Punishment.mp3 is proper! Label is 1 with a probability of 0.775\n",
      "Reinier Zonneveld - Mom Was On Tequila.mp3 is not proper! Label is 0 with a probability of 0.97\n",
      "Alexander Johansson   Mattias Fridell - Retsticka.mp3 is not proper! Label is 0 with a probability of 0.53\n",
      "Mike Parker - Rainmaker.mp3 is proper! Label is 1 with a probability of 0.96\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "track_directory = 'data/'\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for track_name in os.listdir(track_directory):\n",
    "    if track_name.endswith('.mp3'):\n",
    "        track_path = os.path.join(track_directory, track_name)\n",
    "\n",
    "        label, prediction = predict_track(track_path, clf)\n",
    "\n",
    "        if label == 0:\n",
    "            print(f\"{track_name} is not proper! Label is {label[0]} with a probability of {prediction[0][label[0]]}\")\n",
    "        else:\n",
    "            print(f\"{track_name} is proper! Label is {label[0]} with a probability of {prediction[0][label[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09 - Step To Enchantment (Stringent).mp3 is 1 with a probability of 0.73\n"
     ]
    }
   ],
   "source": [
    "# Get prediction over one track\n",
    "track_name = \"09 - Step To Enchantment (Stringent).mp3\"\n",
    "track_path = os.path.join(track_directory, track_name)\n",
    "label, prediction = predict_track(track_path, clf)\n",
    "\n",
    "print(f\"{track_name} is {label[0]} with a probability of {prediction[0][label[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Looks like the model's predictions are only reliable when the quality of the track is not totally messed up. Needs to be decent quality. Not noisy vinyl rips.\n",
    "\n",
    "When we deploy the model as a web app, and users can submit a Youtube link to a track, downloading the audio in high quality will be problematic. \n",
    "\n",
    "We need to find a way to download the audio in high quality. Or, we should downgrade the training data to match the quality of the audio that users can submit from Youtube.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('output/random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)\n",
    "\n",
    "# # Load the model\n",
    "# with open('random_forest_model.pkl', 'rb') as file:\n",
    "#     clf_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [09:15:47] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8775510204081632\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       503\n",
      "           1       0.88      0.88      0.88       526\n",
      "\n",
      "    accuracy                           0.88      1029\n",
      "   macro avg       0.88      0.88      0.88      1029\n",
      "weighted avg       0.88      0.88      0.88      1029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rene Wise - Lakota Fox.mp3 is proper! Label is 1 with a probability of 0.9866272807121277\n",
      "Kike Pravda - Main Control [tZcM4ytxSGc].mp3 is proper! Label is 1 with a probability of 0.9976605176925659\n",
      "Beatrice - I'm Not From Here.mp3 is proper! Label is 1 with a probability of 0.9985795021057129\n",
      "Lowerzone - Verknipt People.mp3 is not proper! Label is 0 with a probability of 0.9979397654533386\n",
      "Mark Dekoda - Rave Harder Techno Bass.mp3 is not proper! Label is 0 with a probability of 0.9347617626190186\n",
      "09 - Step To Enchantment (Stringent).mp3 is proper! Label is 1 with a probability of 0.998744010925293\n",
      "Kaiser (K S R) - Driving In A Fast Tool.mp3 is proper! Label is 1 with a probability of 0.997433602809906\n",
      "Jeff Mills - Step to enchantment [eLtnhsLwSZE].mp3 is not proper! Label is 0 with a probability of 0.9096932411193848\n",
      "Voorman - Surface Scatter.mp3 is proper! Label is 1 with a probability of 0.9994863271713257\n",
      "Stef Mendesidis - Crime and Punishment.mp3 is proper! Label is 1 with a probability of 0.9913327097892761\n",
      "Reinier Zonneveld - Mom Was On Tequila.mp3 is not proper! Label is 0 with a probability of 0.9991275072097778\n",
      "Alexander Johansson   Mattias Fridell - Retsticka.mp3 is not proper! Label is 0 with a probability of 0.6712899804115295\n",
      "Mike Parker - Rainmaker.mp3 is proper! Label is 1 with a probability of 0.9995076656341553\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "track_directory = 'data/'\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for track_name in os.listdir(track_directory):\n",
    "    if track_name.endswith('.mp3'):\n",
    "        track_path = os.path.join(track_directory, track_name)\n",
    "\n",
    "        label, prediction = predict_track(track_path, xgb_model)\n",
    "\n",
    "        if label == 0:\n",
    "            print(f\"{track_name} is not proper! Label is {label[0]} with a probability of {prediction[0][label[0]]}\")\n",
    "        else:\n",
    "            print(f\"{track_name} is proper! Label is {label[0]} with a probability of {prediction[0][label[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression, SVM, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.74%\n",
      "Precision: 0.85\n",
      "Recall: 0.85\n",
      "F1 Score: 0.85\n",
      "Confusion Matrix:\n",
      "[[428  75]\n",
      " [ 82 444]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       503\n",
      "           1       0.86      0.84      0.85       526\n",
      "\n",
      "    accuracy                           0.85      1029\n",
      "   macro avg       0.85      0.85      0.85      1029\n",
      "weighted avg       0.85      0.85      0.85      1029\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train Logistic Regression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "precision = precision_score(y_test, y_pred_logistic, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_logistic, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_logistic, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_logistic)\n",
    "class_report = classification_report(y_test, y_pred_logistic)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.33%\n",
      "Precision: 0.79\n",
      "Recall: 0.78\n",
      "F1 Score: 0.78\n",
      "Confusion Matrix:\n",
      "[[432  71]\n",
      " [152 374]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79       503\n",
      "           1       0.84      0.71      0.77       526\n",
      "\n",
      "    accuracy                           0.78      1029\n",
      "   macro avg       0.79      0.78      0.78      1029\n",
      "weighted avg       0.79      0.78      0.78      1029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "precision = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.73%\n",
      "Precision: 0.82\n",
      "Recall: 0.82\n",
      "F1 Score: 0.82\n",
      "Confusion Matrix:\n",
      "[[424  79]\n",
      " [109 417]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       503\n",
      "           1       0.84      0.79      0.82       526\n",
      "\n",
      "    accuracy                           0.82      1029\n",
      "   macro avg       0.82      0.82      0.82      1029\n",
      "weighted avg       0.82      0.82      0.82      1029\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Train KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "precision = precision_score(y_test, y_pred_knn, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_knn, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_knn)\n",
    "class_report = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression()\n",
      "Rene Wise - Lakota Fox.mp3 is proper! Label is 1 with a probability of 0.8934672488502142\n",
      "Kike Pravda - Main Control [tZcM4ytxSGc].mp3 is proper! Label is 1 with a probability of 0.8806780022623224\n",
      "Beatrice - I'm Not From Here.mp3 is proper! Label is 1 with a probability of 0.9493046722020121\n",
      "Lowerzone - Verknipt People.mp3 is not proper! Label is 0 with a probability of 0.5532544823335399\n",
      "Mark Dekoda - Rave Harder Techno Bass.mp3 is not proper! Label is 0 with a probability of 0.7003384048900274\n",
      "09 - Step To Enchantment (Stringent).mp3 is proper! Label is 1 with a probability of 0.8382499301230181\n",
      "Kaiser (K S R) - Driving In A Fast Tool.mp3 is proper! Label is 1 with a probability of 0.888100460451353\n",
      "Jeff Mills - Step to enchantment [eLtnhsLwSZE].mp3 is proper! Label is 1 with a probability of 0.5456870861280316\n",
      "Voorman - Surface Scatter.mp3 is proper! Label is 1 with a probability of 0.9614647768970976\n",
      "Stef Mendesidis - Crime and Punishment.mp3 is proper! Label is 1 with a probability of 0.5734960617527317\n",
      "Reinier Zonneveld - Mom Was On Tequila.mp3 is not proper! Label is 0 with a probability of 0.9887496145095594\n",
      "Alexander Johansson   Mattias Fridell - Retsticka.mp3 is proper! Label is 1 with a probability of 0.6268221158509374\n",
      "Mike Parker - Rainmaker.mp3 is proper! Label is 1 with a probability of 0.969938810446408\n",
      "Model: SVC(probability=True)\n",
      "Rene Wise - Lakota Fox.mp3 is proper! Label is 1 with a probability of 0.8320277685758578\n",
      "Kike Pravda - Main Control [tZcM4ytxSGc].mp3 is proper! Label is 1 with a probability of 0.8079880635286845\n",
      "Beatrice - I'm Not From Here.mp3 is proper! Label is 1 with a probability of 0.8375724782612218\n",
      "Lowerzone - Verknipt People.mp3 is not proper! Label is 0 with a probability of 0.8637211021450557\n",
      "Mark Dekoda - Rave Harder Techno Bass.mp3 is not proper! Label is 0 with a probability of 0.508906805696861\n",
      "09 - Step To Enchantment (Stringent).mp3 is proper! Label is 1 with a probability of 0.8214185908400188\n",
      "Kaiser (K S R) - Driving In A Fast Tool.mp3 is proper! Label is 1 with a probability of 0.7492403829139126\n",
      "Jeff Mills - Step to enchantment [eLtnhsLwSZE].mp3 is not proper! Label is 0 with a probability of 0.888765903898894\n",
      "Voorman - Surface Scatter.mp3 is proper! Label is 1 with a probability of 0.958850210315641\n",
      "Stef Mendesidis - Crime and Punishment.mp3 is proper! Label is 1 with a probability of 0.6905765097419334\n",
      "Reinier Zonneveld - Mom Was On Tequila.mp3 is not proper! Label is 0 with a probability of 0.919390049805825\n",
      "Alexander Johansson   Mattias Fridell - Retsticka.mp3 is not proper! Label is 0 with a probability of 0.702088808576905\n",
      "Mike Parker - Rainmaker.mp3 is proper! Label is 1 with a probability of 0.7448061956954506\n",
      "Model: KNeighborsClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rene Wise - Lakota Fox.mp3 is proper! Label is 1 with a probability of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kike Pravda - Main Control [tZcM4ytxSGc].mp3 is proper! Label is 1 with a probability of 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beatrice - I'm Not From Here.mp3 is not proper! Label is 0 with a probability of 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowerzone - Verknipt People.mp3 is not proper! Label is 0 with a probability of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Dekoda - Rave Harder Techno Bass.mp3 is not proper! Label is 0 with a probability of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09 - Step To Enchantment (Stringent).mp3 is proper! Label is 1 with a probability of 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaiser (K S R) - Driving In A Fast Tool.mp3 is proper! Label is 1 with a probability of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff Mills - Step to enchantment [eLtnhsLwSZE].mp3 is not proper! Label is 0 with a probability of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voorman - Surface Scatter.mp3 is proper! Label is 1 with a probability of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stef Mendesidis - Crime and Punishment.mp3 is proper! Label is 1 with a probability of 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinier Zonneveld - Mom Was On Tequila.mp3 is not proper! Label is 0 with a probability of 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander Johansson   Mattias Fridell - Retsticka.mp3 is proper! Label is 1 with a probability of 0.6\n",
      "Mike Parker - Rainmaker.mp3 is proper! Label is 1 with a probability of 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zein/opt/miniconda3/envs/proper-classifier/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "track_directory = 'data/'\n",
    "\n",
    "for model in [logistic_model, svm_model, knn_model]:\n",
    "    print(f\"Model: {model}\")\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for track_name in os.listdir(track_directory):\n",
    "        if track_name.endswith('.mp3'):\n",
    "            track_path = os.path.join(track_directory, track_name)\n",
    "\n",
    "            label, prediction = predict_track(track_path, model)\n",
    "\n",
    "            if label == 0:\n",
    "                print(f\"{track_name} is not proper! Label is {label[0]} with a probability of {prediction[0][label[0]]}\")\n",
    "            else:\n",
    "                print(f\"{track_name} is proper! Label is {label[0]} with a probability of {prediction[0][label[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram based CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # 2 classes: proper and improper, so 2 output neurons\n",
    "])\n",
    "\n",
    "#Load images and prepare the training and testing data\n",
    "\n",
    "\n",
    "# Preprocess your data\n",
    "# Assuming X_train and X_test are your image data and y_train, y_test are your labels\n",
    "# Ensure X_train and X_test are reshaped to (num_samples, 128, 128, 3) and normalized\n",
    "X_train = X_train.reshape(-1, 128, 128, 3) / 255.0\n",
    "X_test = X_test.reshape(-1, 128, 128, 3) / 255.0\n",
    "\n",
    "# Convert labels to categorical if they are not already\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proper-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
